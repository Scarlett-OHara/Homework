{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95953f65",
   "metadata": {},
   "source": [
    "pytorch相关环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ae91c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "CUDA version: 12.4\n",
      "PyTorch version: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"PyTorch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f426c35",
   "metadata": {},
   "source": [
    "数据处理相关环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ba012dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37a8d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "config = {    \n",
    "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': False,   # Whether to use all features.\n",
    "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 3000,     # Number of epochs.            \n",
    "    'batch_size': 256, \n",
    "    'learning_rate': 1e-5,              \n",
    "    'early_stop': 400,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './model.ckpt' , # Your model will be saved here.\n",
    "    'feature':[0,1,2,3,4]\n",
    "}\n",
    "#固定随机数种子\n",
    "def same_seed(seed):\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "#划分训练集 验证集\n",
    "def train_valid_split(data_set,valid_ratio,seed):\n",
    "    valid_set_size = int(len(data_set) * valid_ratio) #防止乘ratio为小数\n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set,vaild_set = random_split(data_set,[train_set_size,valid_set_size],generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set),np.array(vaild_set)\n",
    "\n",
    "#测试集测试\n",
    "def predict(test_loader,model,device):\n",
    "    model.eval() #切换模型至评估模式\n",
    "    preds = []\n",
    "\n",
    "    for x in tqdm(test_loader): #tqdm用于显示进度条\n",
    "        x = x.to(device) #指定数据计算位置，cpu,gpu?\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(x) \n",
    "            preds.append(pred.detach().cpu()) #把数从gpu迁移至cpu\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    return preds\n",
    "\n",
    "#分割标签并选择特征\n",
    "def select_feat(train_data,valid_data,test_data,select_all = True):\n",
    "    #提取标签（真实输出）\n",
    "    y_train,y_valid = train_data[:,-1],valid_data[:,-1]\n",
    "    #提取输入,测试集没有输出值\n",
    "    x_train,x_valid,x_test = train_data[:,:-1],valid_data[:,:-1],test_data\n",
    "\n",
    "    if select_all: #选择全部特征作为输入\n",
    "        feat_index = list(range(x_train.shape[1]))\n",
    "    else:\n",
    "        feat_index = list(range(1,x_train.shape[1])) #后续加config\n",
    "\n",
    "    return x_train[:,feat_index],x_valid[:,feat_index],x_test[:,feat_index],y_train,y_valid\n",
    "\n",
    "#print(list((range(5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f51c1",
   "metadata": {},
   "source": [
    "用于获取数据集中数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f250e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset): #重写某些方法，继承并保持某些方法\n",
    "    def __init__(self,x,y=None): #将数据转换成pytorch格式\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        \n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    def __getitem__(self, index): #根据是否有结果返回数据,重写方法\n",
    "        if self.y is None:\n",
    "            return self.x[index]\n",
    "        else:\n",
    "            return self.x[index],self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfde7c3",
   "metadata": {},
   "source": [
    "定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb727d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, inputdims):\n",
    "        super(My_Model,self).__init__() #继承方法并让系统知道这是pytorch的网络结构方便后续优化\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(inputdims,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,1),\n",
    "        )\n",
    "\n",
    "    def forward(self,data):\n",
    "        data = self.layers(data).squeeze(1)\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4b66c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for x,y in train_loader:\\n    for i in range(len(x)):\\n        print(x[i][0])\\n    print(x.shape)\\n'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_seed(config['seed'])\n",
    "\n",
    "train_data,test_data = pd.read_csv('./covid.train.csv').values,pd.read_csv('./covid.test.csv').values\n",
    "'''\n",
    "print(len(train_data) )\n",
    "#print(train_data.type())\n",
    "for i in range(len(train_data)):\n",
    "    print(train_data[i,0])\n",
    "'''\n",
    "#划分数据集\n",
    "train_data,valid_data = train_valid_split(train_data,config['valid_ratio'],config['seed'])\n",
    "#读入数据\n",
    "x_train,x_valid,x_test,y_train,y_valid = select_feat(train_data,valid_data,test_data,select_all=config['select_all'])\n",
    "\n",
    "'''for i in range(len(x_train)):\n",
    "    print(x_train[i,0])\n",
    "'''\n",
    "train_dataset,valid_dataset,test_dataset = COVID19Dataset(x_train,y_train),COVID19Dataset(x_valid,y_valid),COVID19Dataset(x_test)\n",
    "#对数据进行打包，打乱\n",
    "train_loader = DataLoader(train_dataset,batch_size=config['batch_size'],shuffle=True,pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
    "\n",
    "'''for x,y in train_loader:\n",
    "    for i in range(len(x)):\n",
    "        print(x[i][0])\n",
    "    print(x.shape)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c88f88",
   "metadata": {},
   "source": [
    "训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4cb969d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader:DataLoader,valid_loader:DataLoader,model:My_Model,config,device):\n",
    "    \n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=config['learning_rate'],momentum=0.9)\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    n_epochs,best_loss,step,early_stop_count = config['n_epochs'],math.inf,0,0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        loss_record = []\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True) #显示训练进度\n",
    "\n",
    "        for x,y in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred,y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            step = step+1\n",
    "            loss_record.append(loss)\n",
    "\n",
    "            train_pbar.set_description(f'Epoch[{epoch+1}/{n_epochs}]') #进度条前缀说明\n",
    "            train_pbar.set_postfix({'loss':loss.detach().item()}) #显示动态指标\n",
    "            \n",
    "\n",
    "        mean_train_loss = sum(loss_record) / len(loss_record)\n",
    "        writer.add_scalar('train_loss',mean_train_loss,step)\n",
    "\n",
    "        model.eval()\n",
    "        loss_record = []\n",
    "        for x,y in valid_loader:\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred,y)\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "\n",
    "        mean_valid_loss = sum(loss_record) / len(loss_record)\n",
    "        print()\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}\\n')\n",
    "        writer.add_scalar('valid_loss',mean_valid_loss,step)\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(),config['save_path'])\n",
    "            print('Saving model')\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count+=1\n",
    "\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('stop train')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "130b80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x128 and 64x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m My_Model(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 2\u001b[0m trainer(train_loader,valid_loader,model,config,device)\n",
      "Cell \u001b[1;32mIn[116], line 17\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m x,y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device),y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 17\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred,y)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[114], line 15\u001b[0m, in \u001b[0;36mMy_Model.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,data):\n\u001b[1;32m---> 15\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(data)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\ANACONDA\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x128 and 64x32)"
     ]
    }
   ],
   "source": [
    "model = My_Model(x_train.shape[1]).to(device)\n",
    "trainer(train_loader,valid_loader,model,config,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27784c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1788), started 18:03:42 ago. (Use '!kill 1788' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8fcc0bc6b6d3c8ea\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8fcc0bc6b6d3c8ea\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "def84c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 511.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def save_pred(preds, file):\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "test_model = My_Model(inputdims=x_train.shape[1]).to(device)\n",
    "test_model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader,model,device)\n",
    "save_pred(preds,'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d2411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
